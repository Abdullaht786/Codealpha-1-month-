# -*- coding: utf-8 -*-
"""Car Price Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/car-price-prediction-58888154-85eb-4f7d-bc94-2f240bd14f5e.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240929/auto/storage/goog4_request%26X-Goog-Date%3D20240929T104629Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D35e197d627897435ff71da56803dbe7f501d115cb5f06be66206a821c4d8083d086c7ee67e6d02c308cd2565f939fb9678278e91ae5183c35293ce66cba6e64e4fbf212d9d5ad41eccce0c79b5e80e0d028813ffc0b483c43a4baa581fa48e23f78051b9e9652079b5c761022033eb5f3116087906746f0f402425a0abcef324449f4f90a09562e48987c16b402ac59633b7610c010bd31c764e2d006139a1f5ff189eaae3ebd9e804467a50c065356248fde96dc1c0556c32ee92b4995767f334db3935bf25e22e57d44bcbe157b7ec7e0e3aa92c063ac6dba1945c6c045e2c70d55944c815637f4bfd13ad36f6b699d3074df8ad0a49480be001ea90cc3a52
"""



# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

"""> # **Car Price Prediction**

# **Import Libraries**
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

"""# **Import Dataset**"""

df = pd.read_csv('/kaggle/input/car-price-predictionused-cars/car data.csv')
df

"""# **Data Preprocessing**"""

df.head()

df.tail()

df.columns

df.info()

display(df.describe())

df.shape

df.duplicated().any()

duplicate_values = df.duplicated().sum()
duplicate_values

null_values = df.isna().sum()
null_values

df.drop_duplicates(inplace= True)

"""# **Exploratory Data Analysis**"""

df.hist(figsize  = (12,12))

numerical_columns = ['Year', 'Selling_Price', 'Present_Price', 'Driven_kms', 'Owner']

numerical_df = df[numerical_columns]

corr_matrix = numerical_df.corr()

corr_matrix

plt.figure(figsize=(6,6))
sns.heatmap(corr_matrix, annot=True, cmap='pink',  linewidths=1,fmt=".2f")
plt.title('Feature Correlation Heatmap')
plt.show()

"""1. Selling price and present price show a strong positive correlation which means present price of cars likely influences selling price.
2. year and Driven kms show a negative correlation which means cars which are newer(lower in year value) will have lower mileage and wlillm more sell.
"""

import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
sns.pairplot(df[['Present_Price', 'Year', 'Driven_kms', 'Selling_Price']])
plt.show()

columns = ['Fuel_Type', 'Transmission', 'Owner', 'Selling_type']

for column in columns:
    plt.figure(figsize = (5,4))
    sns.countplot(x = column, data = df)
    plt.title(f'this is a count plot of {column}')
    plt.xticks(rotation=90)
    plt.show()

sns.boxplot(df['Selling_Price'])
plt.title('Selling Price Distribution')
plt.show()

sns.boxplot(df['Present_Price'])
plt.title('Present Price Distribution')
plt.show()

"""# **Feature Engineering¶**"""

df['Car_Age'] = 2024 - df['Year']
df.head()

"""# **Data Transformation**"""

df.dtypes

df['Fuel_Type'].value_counts()

df['Selling_type'].value_counts()

df['Transmission'].value_counts()

ordinal_map = {'CNG':2,'Diesel':1,'Petrol':0}
df['Fuel_Type'] = df['Fuel_Type'].map(ordinal_map)
df['Fuel_Type'] = df['Fuel_Type'].astype('int64')

df = pd.get_dummies(df, columns = ['Selling_type','Transmission'])

df.dtypes

bool_columns = ['Selling_type_Dealer','Selling_type_Individual', 'Transmission_Automatic', 'Transmission_Manual']

df[bool_columns] = df[bool_columns].astype('int64')

df.head()

"""# **Model Building¶**"""

X = df.drop(['Car_Name','Selling_Price'],axis=1)
y = df['Selling_Price']

X.head()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score

def evaluation(y, predictions):
    return {
        'MAE': mean_absolute_error(y, predictions),
        'MSE': mean_squared_error(y, predictions),
        'RMSE': np.sqrt(mean_squared_error(y, predictions)),
        'R-squared': r2_score(y, predictions)
    }

"""## **Linear Regression Model**"""

from sklearn.linear_model import LinearRegression

model_name = "LinearRegression"

# Build a Linear Regression model
lin_reg = LinearRegression()

# Fit the model on the training data
lin_reg.fit(X_train, y_train)

# Predict using the model on the data
predictions = lin_reg.predict(X_test)

# Function call to Evaluate results of 'MAE', 'MSE', 'RMSE', 'R-squared'
evaluation_results_l = evaluation(y_test, predictions)

evaluation_results_l["Model"] = model_name


models = pd.DataFrame([evaluation_results_l])

print("Evaluation Results for", model_name)
print('-'*30)
for metric, value in evaluation_results_l.items():
    print(f"{metric}: {value}")

"""## **Random Forest Model**"""

from sklearn.ensemble import RandomForestRegressor

model_name = "RandomForest"

# Build a Random Forest model
rand_for = RandomForestRegressor(n_estimators=100, random_state=0)

# Fit the model on the training data
rand_for.fit(X_train, y_train)

# Predict using the model on the test data
predictions = rand_for.predict(X_test)

# Function call to Evaluate results of 'MAE', 'MSE', 'RMSE', 'R-squared'
evaluation_results_r = evaluation(y_test, predictions)


evaluation_results_r["Model"] = model_name


models = pd.DataFrame([evaluation_results_r])

print("Evaluation Results for", model_name)
print('-'*30)
for metric, value in evaluation_results_r.items():
    print(f"{metric}: {value}")

"""## **Gradient Regressor Model**"""

from sklearn.ensemble import GradientBoostingRegressor

model_name = "GradientBoostingRegressor"

# Build a Gradient Boost model
g_boost = GradientBoostingRegressor(random_state=0)

# Fit the model on the training data
g_boost.fit(X_train, y_train)

# Predict using the model on the test data
predictions = g_boost.predict(X_test)

# Function call to Evaluate results of 'MAE', 'MSE', 'RMSE', 'R-squared'
evaluation_results_g = evaluation(y_test, predictions)

evaluation_results_g["Model"] = model_name

models = pd.DataFrame([evaluation_results_g])

print("Evaluation Results for", model_name)
print('-'*30)
for metric, value in evaluation_results_g.items():
    print(f"{metric}: {value}")

"""## **Models Comparison¶**"""

model_results = [
    {"model": "LinearRegression", "r2 score": evaluation_results_l['R-squared']},
    {"model": "RandomForestRegressor", "r2 score": evaluation_results_r['R-squared']},
    {"model": "XGBRegressor", "r2 score": evaluation_results_g['R-squared']},
]

#sort models according to there results
sorted_results = sorted(model_results, key=lambda x: x["r2 score"])

# Print the sorted results
for result in sorted_results:
    print(result)

model_names = [model["model"] for model in model_results]
rmse_values = [model["r2 score"] for model in model_results]

plt.figure(figsize=(8, 4))
plt.bar(model_names, rmse_values, color=['green', 'blue', 'orange'])
plt.xlabel('Models')
plt.ylabel('r2 score')
plt.title('Comparison of r2 score Values for Different Models')
plt.show()

"""The results are clear that **linear regression model** is giving good performance as its r2 score is higher compared to other models."""